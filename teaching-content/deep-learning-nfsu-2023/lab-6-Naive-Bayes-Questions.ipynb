{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3059eb7",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7f7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1858ff4b",
   "metadata": {},
   "source": [
    "$$ P(Class | Sample) = \\frac{P(Sample | Class) \\times P(Class)}{P(Sample)} $$ </br>\n",
    "\n",
    "$$posterior = \\frac{likelihood \\times prior}{evidence}$$ </br>\n",
    "\n",
    "$$P(c_i | x_j) \\propto P(x_j|c_i) \\times P(c_i)$$ </br>\n",
    "\n",
    "For categorical features, we can use a Multinouilli distribution, where $\\mu_{ic}$ is an histogram over the possible values for $x_i$ in class $c$ : </br>\n",
    "\n",
    "\n",
    "$$P(\\textbf{x} | c) = \\prod_{i=1}^{D} Cat (x_j | \\mu_{jc})$$ </br>\n",
    "\n",
    "\n",
    "**During Training**:\n",
    " - Compute the prior probability i.e $p(c_i)$ the proportion of samples inside each class of the whole training set.\n",
    " - for each feature:\n",
    "  - if the feature is categorical, compute $p(x_j | c_i)$ for $j=1,2 \\ldots D$ and $i=1,2 \\ldots C$\n",
    "       - for each possible values of this feature in the training samples of class $c_i$ compute the probability that this feature appear in class $c_i$\n",
    "\n",
    "**To Predict**\n",
    " - Compute $p(c_i | \\textbf{x})$\n",
    "  - Multiply the prior of each class $p(c_i)$ by\n",
    "  - for each feature $\\textbf{k}$:\n",
    "      - if categorical, multiply by the probabilities calculated earlier, $p(x_k | c_i)$ where $x_k$ is the value of the input on feature $k$\n",
    "  - return the highest probability $p(c_i | x)$ of all classes \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f7c41a",
   "metadata": {},
   "source": [
    "### Q1: 5 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b4d0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play Tennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Outlook Temperature Humidity    Wind Play Tennis\n",
       "0     Sunny         Hot     High    Weak          No\n",
       "1     Sunny         Hot     High  Strong          No\n",
       "2  Overcast         Hot     High    Weak         Yes\n",
       "4      Rain        Cool   Normal    Weak         Yes\n",
       "5      Rain        Cool   Normal  Strong          No"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 marks. 2.5 Marks X 2\n",
    "\n",
    "df = pd.read_csv(\"PlayTennis.csv\")\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = #write your code here\n",
    "test = #write your code here\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570f181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Marks.\n",
    "# create the dict data structure\n",
    "_class = 'Play Tennis'\n",
    "di = {}\n",
    "for class_label in train[_class].unique():\n",
    "    #write your code to create the dictionary as shown in the net cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af220b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': {'Outlook': {'Sunny': 0, 'Overcast': 0, 'Rain': 0},\n",
       "  'Temperature': {'Hot': 0, 'Cool': 0, 'Mild': 0},\n",
       "  'Humidity': {'High': 0, 'Normal': 0},\n",
       "  'Wind': {'Weak': 0, 'Strong': 0}},\n",
       " 'Yes': {'Outlook': {'Sunny': 0, 'Overcast': 0, 'Rain': 0},\n",
       "  'Temperature': {'Hot': 0, 'Cool': 0, 'Mild': 0},\n",
       "  'Humidity': {'High': 0, 'Normal': 0},\n",
       "  'Wind': {'Weak': 0, 'Strong': 0}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f1206",
   "metadata": {},
   "source": [
    "### Q2: 10 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d78f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Marks. 5 marks X 2\n",
    "# The expected output can be seen in the next cell.\n",
    "classLabel = 'Yes'\n",
    "\n",
    "for classLabel in ['Yes', 'No']:\n",
    "    for feature in train.columns:\n",
    "            if feature != _class:\n",
    "                for item in train[feature].unique():\n",
    "                    numr = # write your code here\n",
    "                    denr = # write your code here\n",
    "                    di[classLabel][feature][item] = numr/denr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02dfb676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'No': {'Outlook': {'Sunny': 0.6666666666666666,\n",
       "   'Overcast': 0.0,\n",
       "   'Rain': 0.3333333333333333},\n",
       "  'Temperature': {'Hot': 0.6666666666666666,\n",
       "   'Cool': 0.3333333333333333,\n",
       "   'Mild': 0.0},\n",
       "  'Humidity': {'High': 0.6666666666666666, 'Normal': 0.3333333333333333},\n",
       "  'Wind': {'Weak': 0.3333333333333333, 'Strong': 0.6666666666666666}},\n",
       " 'Yes': {'Outlook': {'Sunny': 0.2857142857142857,\n",
       "   'Overcast': 0.5714285714285714,\n",
       "   'Rain': 0.14285714285714285},\n",
       "  'Temperature': {'Hot': 0.2857142857142857,\n",
       "   'Cool': 0.42857142857142855,\n",
       "   'Mild': 0.2857142857142857},\n",
       "  'Humidity': {'High': 0.2857142857142857, 'Normal': 0.7142857142857143},\n",
       "  'Wind': {'Weak': 0.5714285714285714, 'Strong': 0.42857142857142855}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "di"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9020e7",
   "metadata": {},
   "source": [
    "### Q3: 5 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6ffcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.3\n"
     ]
    }
   ],
   "source": [
    "# Code to Mimic Testing\n",
    "P_Yes = # write your code here\n",
    "P_No = # write your code here\n",
    "print(P_Yes, P_No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35556c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes = []\n",
    "no = []\n",
    "\n",
    "for Label in ['Yes', 'No']:\n",
    "    for index, row in test.iterrows():\n",
    "        value = P_Yes if Label == 'Yes' else P_No\n",
    "        for feature in test.columns:\n",
    "            if feature != _class:\n",
    "                value*=di[Label][feature][row[feature]]\n",
    "        yes.append(value) if Label == 'Yes' else no.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01e8c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00466472303206997,\n",
       " 0.00932944606413994,\n",
       " 0.011661807580174925,\n",
       " 0.0034985422740524776]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0fb5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b57560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Yes', 'Yes', 'Yes', 'Yes']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Predicted Labels\")\n",
    "predicted_labels = []\n",
    "for item in zip(yes, no):\n",
    "    predicted_labels.append(\"Yes\" if item[0]>item[1] else \"No\")\n",
    "    #print(\"Yes\") if item[0]>item[1] else print(\"No\")\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6a7436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Yes', 'No', 'Yes', 'No']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"True Labels\")\n",
    "list(test[_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70386c24",
   "metadata": {},
   "source": [
    "### Q4: 5 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "454a333f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "# write your code to find out the accuracy between predicted and true labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9ebe89",
   "metadata": {},
   "source": [
    "### Lets compare our result with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e705295",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cad10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "data_train_df = pd.DataFrame(train)\n",
    "data_train_df_encoded = data_train_df.apply(le.fit_transform)\n",
    "\n",
    "data_test_df = pd.DataFrame(test)\n",
    "data_test_df_encoded = data_test_df.apply(le.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59984377",
   "metadata": {},
   "source": [
    "### Q5: 10 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d0caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = # write your code here to drop \"Play Tennis Feature\"\n",
    "y_train = # write your code here to drop \"Play Tennis Feature\"\n",
    "\n",
    "x_test = data_test_df_encoded.drop(['Play Tennis'],axis=1)\n",
    "y_test = data_test_df_encoded['Play Tennis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1a50a",
   "metadata": {},
   "source": [
    "### Q6: 5 Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e7029c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "model = # write your code here\n",
    "nbtrain = model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = nbtrain.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b48555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
